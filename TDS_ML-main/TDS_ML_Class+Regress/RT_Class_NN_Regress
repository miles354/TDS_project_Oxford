# Libraries and imports for simulation and machine learning
import TDS_Sim
import numpy as np
import random
import matplotlib.pyplot as plt
import joblib
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, roc_curve, auc
from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler
import seaborn as sns
from itertools import cycle
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import r2_score

# STEP 1: GENERATE SYNTHETIC TDS DATA
NumSamples = 4000  # Number of samples to generate
n_cpu_cores = 5  # Number of CPU cores to use for simulations

def takeSecond(elem):
    return elem[1]

def GenerateDataPoint(i):
    PlotWhileSolving = False  # Whether to generate plots when simulating (much slower)
    model = "Rates"  # Currently using Mcnabb-Foster
    NumTraps = random.randint(1, 3)  # Number of trapping sites

    N_Elements = 10  # For obtaining the solution, number of linear finite elements used
    dT_Step = 120.0  # Time increment used

    Thickness = 10.0e-3  # Sample thickness

    Diff_RT = 1.0e-9  # Diffusion rate at room temperature
    E_diff = 2*4.0e3  # Diffusion energy (used for temperature scaling)

    k_T  = [1.0e4, 1.0e0]  # Boundary flux absorption-desorption rates

    time_Charge = 12.0*3600.0  # Time left charging
    Temp_Charge = 273.15+20.0  # Temperature at which samples are charged
    pCharge = 1.0e6  # Hydrogen fugacity during charging

    time_rest = 600.0  # Time sample is being transferred from charging to TDS

    TDS_HeatingRate = 1.0/60.0  # Heating rate of TDS
    TDS_Time = 3600.0*24  # Total time over which TDS is performed

    # Generate trapping energies
    traps = []
    for t in range(0, NumTraps):
        validPoint = False
        while not validPoint:
            E_abs = 20.0e3
            E_des = random.uniform(40.0e3, 150.0e3)
            N = random.uniform(30.0, 100.0)

            # Make sure energies are slightly distinct
            goodDist = True
            for E in traps:
                if abs(E[1] - E_des) < 10e3:
                    goodDist = False
            validPoint = goodDist

        traps.append([E_abs, E_des, N])
        traps.sort(key=takeSecond)

    # Save trapping sites and energies as vectors
    N_traps = []
    E_traps = []
    for t in traps:
        N_traps.append(t[2])
        E_traps.append([t[0], t[1]])

    print(str(i) + ":")
    print("\t N=" + str(N_traps))
    print("\t E=" + str(E_traps))

    # Perform TDS experiment within simulation
    Sample = TDS_Sim.TDS_Sample(Thickness, N_Elements, dT_Step, PlotWhileSolving)  # Initializes material
    Sample.Set_Params(model, Diff_RT, E_diff, N_traps, E_traps, k_T)  # Sets material parameters
    Sample.Charge(time_Charge, Temp_Charge, pCharge)  # Performs charging
    Sample.Rest(time_rest)  # Leave at atmospheric pressure
    T, J = Sample.TDS(TDS_Time, TDS_HeatingRate)  # Perform TDS

    return NumTraps, N_traps, E_traps, T, J

# Generate synthetic TDS data
if __name__ == "__main__":
    # Run simulations in parallel
    Res = joblib.Parallel(n_jobs=n_cpu_cores)(joblib.delayed(GenerateDataPoint)(i) for i in range(NumSamples))

    # Extract features and labels
    Sample_NTraps = [res[0] for res in Res]
    SampleResults = [res[3:] for res in Res]
    Sample_E_Traps = [res[2] for res in Res]

    Features = []  # Features extracted from the TDS curves for model training
    Labels = []  # Labels (number of traps) for classification

    for i in range(NumSamples):
        Labels.append(Sample_NTraps[i])
        T = np.interp(np.linspace(0, len(SampleResults[i][0])-1, num=100), np.arange(len(SampleResults[i][0])), SampleResults[i][1])
        Features.append(T)

    # Convert lists to numpy arrays
    Features = np.array(Features)
    Labels = np.array(Labels)

# STEP 2: TRAIN RANDOM FOREST CLASSIFIER TO PREDICT NUMBER OF TRAPS
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(Features, Labels, train_size=0.8, test_size=0.2, random_state=42)

    # Create and train a Random Forest Classifier
    rf_clf = RandomForestClassifier(n_estimators=500, max_depth=50, random_state=42)
    rf_clf.fit(X_train, y_train)

    # Make predictions on the test data
    y_pred = rf_clf.predict(X_test)

    # Evaluate the model's performance
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)
    print("Classification Accuracy:", accuracy)
    print("Classification Report:\n", report)

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred, labels=[1, 2, 3])
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3], yticklabels=[1, 2, 3])
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix for Number of Traps Prediction with Random Forest')
    plt.savefig("RT_Confusion_Matrix.png")
    plt.show()

    # AUC-ROC curve plotting
    y_prob = rf_clf.predict_proba(X_test)
    y_test_bin = label_binarize(y_test, classes=[1, 2, 3])
    n_classes = y_test_bin.shape[1]

    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    plt.figure()
    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
    for i, color in zip(range(n_classes), colors):
        plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve of class {i + 1} (area = {roc_auc[i]:0.2f})')

    plt.plot([0, 1], [0, 1], 'k--', lw=2)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    plt.savefig("RT_AUC_ROC_Curves.png", dpi=600)
    plt.show()

# STEP 3: NEURAL NETWORK REGRESSOR TO QUANTIFY ENERGY
    Energy_Features = []
    Energy_Labels = []

    for i in range(NumSamples):
        NumTraps = Res[i][0]
        E_traps = Res[i][2]
        T = np.interp(np.linspace(0, len(Res[i][3])-1, num=100), np.arange(len(Res[i][3])), Res[i][3])

        for trap_index in range(NumTraps):
            energy_features = np.concatenate((T, np.array(E_traps[trap_index])))
            Energy_Features.append(energy_features)
            Energy_Labels.append(E_traps[trap_index])

    Energy_Features = np.array(Energy_Features)
    Energy_Labels = np.array(Energy_Labels)

    X_train_energy, X_test_energy, y_train_energy, y_test_energy = train_test_split(Energy_Features, Energy_Labels, train_size=0.8, test_size=0.2, random_state=42)

    # Train Neural Network Regressor
    scaler = StandardScaler()
    X_train_energy_scaled = scaler.fit_transform(X_train_energy)
    X_test_energy_scaled = scaler.transform(X_test_energy)

    
    model = models.Sequential()
    model.add(layers.Dense(128, activation='relu', input_shape=(X_train_energy.shape[1],)))
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(32, activation='relu'))
    model.add(layers.Dense(16, activation='relu'))
    model.add(layers.Dense(8, activation='relu'))
    model.add(layers.Dense(2))

    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    history = model.fit(X_train_energy_scaled, y_train_energy, epochs=500, validation_data=(X_test_energy_scaled, y_test_energy))

    y_pred_nn_energy = model.predict(X_test_energy_scaled)
    nn_mse = mean_squared_error(y_test_energy, y_pred_nn_energy)
    print("Neural Network Regressor Mean Squared Error:", nn_mse)

    nn_r2 = r2_score(y_test_energy, y_pred_nn_energy)
    print("Neural Network Regressor R^2 Score:", nn_r2)

    plt.plot(history.history['loss'], label='train_loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Training and Validation Loss (Neural Network Regressor)')
    plt.savefig("NN_Training_Validation_Loss.png", dpi=600)
    plt.show()

    # Your existing scatter plot
    plt.scatter(y_test_energy[:, 1], y_pred_nn_energy[:, 1], alpha=0.5)

    # Compute the line of best fit
    m, b = np.polyfit(y_test_energy[:, 1], y_pred_nn_energy[:, 1], 1)
    best_fit_line = np.polyval([m, b], y_test_energy[:, 1])

    #Plot the line of best fit
    plt.plot(y_test_energy[:, 1], best_fit_line, color='red', linestyle='--')

    # Add the equation of the line to the plot
    plt.text(x=0.05, y=0.95, s=f'Line of Best Fit: y = {m:.2f}x + {b:.2f}', 
    transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')

    # Labeling and saving the plot
    plt.xlabel("True Desorption Energies (J/mol)")
    plt.ylabel("Predicted Desorption Energies (J/mol)")
    plt.title("True vs Predicted Desorption Energies (Neural Network Regressor)")
    plt.savefig("NN_True_vs_Predicted_Energies.png", dpi=600)
    plt.show()
